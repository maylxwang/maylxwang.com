The Boeing 737 MAX's MCAS system caused two crashes within five months: Lion Air Flight 610 in October 2018 and Ethiopian Airlines Flight 302 in March 2019. 346 people died. MCAS, the Maneuvering Characteristics Augmentation System, was designed to compensate for aerodynamic changes introduced by the MAX's larger engines. It relied on a single angle-of-attack sensor, could repeatedly pitch the nose down upon faulty sensor readings, and was not disclosed to pilots or included in training materials.

The most precise way to frame the central ethical question is not "Was MCAS ethical?" but rather: "Should Boeing certification engineers have refused to approve MCAS given single-sensor dependency and no pilot notification requirements?" This framing identifies the decision-makers, the specific technical concern, and the communication failure. It also reflects the regulatory context: the FAA had delegated much of its certification authority to Boeing, creating a situation where engineers were simultaneously serving their employer and acting as de facto regulators.

Evaluating this question requires separating documented facts from reasonable assumptions. Boeing's own risk analysis flagged MCAS activation as a potential catastrophic failure mode, and internal communications suggest awareness of the system's erratic behavior during development. What remains uncertain is exactly what engineers communicated to management and how those concerns were received. Given the documented pattern of schedule and cost pressure, it's reasonable to assume some engineers raised concerns that were either dismissed or never escalated.

Definitional ambiguity further complicates judgment. "Transparency," for instance, meant different things to different stakeholders. Boeing treated it as meeting legal disclosure requirements; crash victims' families would define it as proactively sharing safety-critical information in accessible terms. If transparency means mere compliance, Boeing arguably met the standard. If it means ensuring genuine understanding, they clearly did not.

These ambiguities ultimately collide with ASME's ethical canons. Canon 1 holds public safety paramount; Canon 4 requires faithful service to employers. The hierarchy is clear: in life-critical systems, safety overrides employer loyalty. But stating this principle is easier than acting on it. Engineers at Boeing faced a corporate culture that prioritized schedule, regulatory ambiguity that made minimum compliance feel sufficient, and information silos that obscured MCAS's full risk profile. These constraints don't excuse the outcome, but they explain how reasonable people failed to act on principles they likely held. The lesson is not simply "prioritize safety" but that institutions must be designed to make ethical action possible.